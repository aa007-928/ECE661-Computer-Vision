# -*- coding: utf-8 -*-
"""CV_HW6_f.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tYEgG4xPhOwR6e5LBi2hKY1mPO6T8S8I
"""

import numpy as np
import matplotlib.pyplot as plt
import cv2 as cv
from skimage import io, draw
from scipy import optimize

# Otsu's algo -> get threshold
def Otsu_thres(img):

    hist, bin_edg = np.histogram(img,bins=256,range=(0,256))
    hist = hist/sum(hist)

    max_sig = 0
    threshold_opt = 0
    for t in range(256):
        P1, P2 = np.sum(hist[:t]), np.sum(hist[t:])
        if P1 and P2:
            m1, m2 = np.sum(bin_edg[:t]*hist[:t])/P1, np.sum(bin_edg[t:-1]*hist[t:])/P2
            sig = P1*P2*((m1-m2)**2)
            if sig>max_sig:
                max_sig = sig
                threshold_opt = t

    return threshold_opt

#image segmentation using RGB. I/P param: img-image ; iter - #iterations (list of length 3); inv - boolean list len 3 for inverting
def ImgSegment_RGB(img,iter,inv):
    mask_list = []
    for c in range(img.shape[2]):
        img_data = img[:,:,c]
        #img_data = cv.GaussianBlur(img_data, (5, 5), 0)
        for i in range(iter[c]):
            thres = Otsu_thres(img_data)
            if inv[c]:
                mask = img[:,:,c] < thres
            else:
                mask = img[:,:,c] >= thres
            img_data = img[:,:,c][mask]
        mask_list.append(mask)
    comb_mask = np.logical_and.reduce(mask_list)

    plt.imshow(mask_list[0]*255,cmap='gray')
    plt.title('mask ch1')
    plt.show()
    plt.imshow(mask_list[1]*255,cmap='gray')
    plt.title('mask ch2')
    plt.show()
    plt.imshow(mask_list[2]*255,cmap='gray')
    plt.title('mask ch3')
    plt.show()
    plt.imshow(comb_mask*255,cmap='gray')
    plt.title('combined mask')
    plt.show()

    # cv.imwrite('test1.jpeg',comb_mask*255)

    return comb_mask

#extract textual feature. Param N is window size
def textual_feature(gray_img,N):
    var_map = np.zeros(gray_img.shape,dtype=float)
    padded_img = np.pad(gray_img,N//2,constant_values=0)
    for i in range(gray_img.shape[0]):
        for j in range(gray_img.shape[1]):
            window = padded_img[i:i+N,j:j+N]
            window_var = np.var(window)
            var_map[i,j] = window_var
    var_map = (((var_map - np.min(var_map)) / (np.max(var_map)-np.min(var_map)))*255).astype(np.uint8)
    return var_map

#Texture-based segmentation. Param window_size is list of window sizes (i.e N) ; iter-#iterations ; inv-invert
def ImgSegment_features(img,window_size,iter,inv):
    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    feature_maps = [textual_feature(gray_img,N) for N in window_size]
    mask_list=[]
    for i in range(len(feature_maps)):
        img_data = feature_maps[i]
        for j in range(iter[i]):
            thres = Otsu_thres(img_data)
            if inv[i]:
                mask = feature_maps[i] < thres
            else:
                mask = feature_maps[i] >= thres
            img_data = feature_maps[i][mask]
        mask_list.append(mask)
    comb_mask = np.logical_and.reduce(mask_list)

    plt.imshow(mask_list[0]*255,cmap='gray')
    plt.title(f'mask N = {window_size[0]}')
    plt.show()
    plt.imshow(mask_list[1]*255,cmap='gray')
    plt.title(f'mask N = {window_size[1]}')
    plt.show()
    plt.imshow(mask_list[2]*255,cmap='gray')
    plt.title(f'mask N = {window_size[2]}')
    plt.show()
    plt.imshow(comb_mask*255,cmap='gray')
    plt.title('combined mask')
    plt.show()

    # cv.imwrite('test1.jpeg',comb_mask*255)

    return comb_mask

#extract contour based on neighbours
def extract_contour(img_mask):
    h,w = img_mask.shape
    contour_img = np.zeros((h,w),dtype=np.uint8)
    padded_img_mask = np.pad(img_mask,1,constant_values=0)
    for i in range(h):
        for j in range(w):
            window = padded_img_mask[i-1:i+2,j-1:j+2]
            if 0<np.sum(window)<9:
                contour_img[i,j]=1

    plt.imshow(contour_img*255,cmap='gray')
    plt.title('contour')
    plt.show()

#contour using diff. of image and eroded image
def extract_boundary(img_mask):
    k = 4
    kernel = np.ones((k,k),dtype=np.uint8)
    eroded_img_mask = cv.erode(np.float32(img_mask),kernel,iterations=1)
    contour_img = img_mask - eroded_img_mask

    plt.imshow(contour_img*255,cmap='gray')
    plt.title('boundary')
    plt.show()

def ImgSegment_RGB_wContours(img,iter,inv):
  comb_mask = ImgSegment_RGB(img,iter,inv)
  extract_contour(comb_mask)
  extract_boundary(comb_mask)

def ImgSegment_features_wContours(img,window,iter,inv):
  comb_mask = ImgSegment_features(img,window,iter,inv)
  extract_contour(comb_mask)
  extract_boundary(comb_mask)



image1 = cv.imread('/content/dog_small.jpg')
image2 = cv.imread('/content/flower_small.jpg')
image3 = cv.imread('/content/bird1.jpg')
image4 = cv.imread('/content/plane.jpg')
image5 = cv.imread('/content/cat.jpg')

ImgSegment_RGB_wContours(image1,[2,2,2],[1,1,1])
ImgSegment_features_wContours(image1,[3,5,7],[5,4,4],[1,1,1])
ImgSegment_RGB_wContours(image2,[2,2,2],[0,0,0])
ImgSegment_features_wContours(image2,[3,5,7],[2,2,2],[1,1,1])
#ImgSegment_features_wContours(image2,[11,13,15],[1,1,1],[0,0,0])
ImgSegment_RGB_wContours(image3,[2,1,1],[1,1,0])
ImgSegment_features_wContours(image3,[3,5,7],[2,1,1],[1,1,1])
#ImgSegment_features_wContours(image3,[5,7,9],[1,1,1],[0,0,0])
ImgSegment_RGB_wContours(image4,[1,1,1],[1,1,1])
ImgSegment_features_wContours(image4,[3,5,7],[4,4,4],[1,1,1])