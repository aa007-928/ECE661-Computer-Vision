# -*- coding: utf-8 -*-
"""cascaded_AdaBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gEa89fc9EzLOhEFpwCgga_-zFGA3JVsC

Task 3
"""

!unzip /content/CarDetection.zip



import numpy as np
import matplotlib.pyplot as plt
import cv2 as cv
import os

carDet_dataPath = ''

def load_data(root,dirName,category):
    data_path = os.path.join(root,dirName,category)
    data_dir = sorted(os.listdir(data_path))
    img_data = []
    for img_name in data_dir:
        img_path = os.path.join(data_path,img_name)
        img = cv.imread(img_path,cv.IMREAD_GRAYSCALE)
        img_data.append(img)
    labels = np.ones(len(img_data)) if category=='positive' else np.zeros(len(img_data))
    return labels, np.array(img_data)

y_train_pos, x_train_pos = load_data(carDet_dataPath,'train','positive')
y_train_neg, x_train_neg = load_data(carDet_dataPath,'train','negative')
y_test_pos, x_test_pos = load_data(carDet_dataPath,'test','positive')
y_test_neg, x_test_neg = load_data(carDet_dataPath,'test','negative')

x_train_pos_INT = np.array([(cv.integral(x_train_pos[i]))[1:,1:] for i in range(len(x_train_pos))])
x_train_neg_INT = np.array([(cv.integral(x_train_neg[i]))[1:,1:] for i in range(len(x_train_neg))])
x_test_pos_INT = np.array([(cv.integral(x_test_pos[i]))[1:,1:] for i in range(len(x_test_pos))])
x_test_neg_INT = np.array([(cv.integral(x_test_neg[i]))[1:,1:] for i in range(len(x_test_neg))])

def window_sum_val(img_INT,i,j,h,w):
    I1 = img_INT[i,j]
    I2 = img_INT[i+h-1,j]
    I3 = img_INT[i,j+w-1]
    I4 = img_INT[i+h-1,j+w-1]
    return I4-I2-I3+I1

def Haar_features(img_INT):
    #using 2 rectangle features

    #feature type1 - horizontal
    H,W = img_INT.shape
    feature_list1 = []
    for i in range(1,H):
        for j in range(1,W):
            for h in range(1,H-i+1):
            # h=1
              for w in range(1,((W-j+1)//2)):
                  S1 = window_sum_val(img_INT,i,j,h,w)
                  S2 = window_sum_val(img_INT,i,j+w,h,w)
                  feature_list1.append(S1-S2)

    #feature type2 - vertical
    feature_list2 = []
    for i in range(1,H):
        for j in range(1,W):
            for w in range(1,W-j+1):
            # w=1
              for h in range(1,((H-i+1)//2)):
                  S1 = window_sum_val(img_INT,i,j,h,w)
                  S2 = window_sum_val(img_INT,i+h,j,h,w)
                  feature_list2.append(S2-S1)

    feature_list = feature_list1 + feature_list2

    return np.array(feature_list)

def features_dataset(INT_dataset,fname):
    features_list = []
    for img_INT in INT_dataset:
        features_list.append(Haar_features(img_INT))
    features_list = np.array(features_list)
    np.savez_compressed(f'Haar_features_data/{fname}',features_list)
    return features_list

x_train_pos_F = features_dataset(x_train_pos_INT,'x_train_pos_F')
x_train_neg_F = features_dataset(x_train_neg_INT,'x_train_neg_F')
x_test_pos_F = features_dataset(x_test_pos_INT,'x_test_pos_F')
x_test_neg_F = features_dataset(x_test_neg_INT,'x_test_neg_F')

X_train_F = np.vstack((x_train_pos_F,x_train_neg_F))
y_train_F = np.hstack((y_train_pos,y_train_neg))
X_test_F = np.vstack((x_test_pos_F,x_test_neg_F))
y_test_F = np.hstack((y_test_pos,y_test_neg))

def get_weak_classifier(X,y,wts):
    wts = wts/np.sum(wts)
    min_err_seen = np.inf
    for f_idx in range(X.shape[1]):
        feature = X[:,f_idx]
        sort_idx = np.argsort(feature)
        sorted_feature = feature[sort_idx]
        sorted_wts = wts[sort_idx]
        sorted_y = y[sort_idx]

        pos_cumsum = np.cumsum(sorted_wts*sorted_y)
        neg_cumsum = np.cumsum(sorted_wts) - pos_cumsum
        total_pos_wts = np.sum(sorted_wts[sorted_y==1])
        total_neg_wts = np.sum(sorted_wts[sorted_y==0])

        error1 = pos_cumsum + total_neg_wts - neg_cumsum    #error assosciated with polarity 1
        error2 = neg_cumsum + total_pos_wts - pos_cumsum    #error assosciated with polarity -1

        min_error_idx = np.argmin(np.minimum(error1,error2))
        min_error = np.min(np.minimum(error1,error2))
        thres = sorted_feature[min_error_idx]

        if min_error<min_err_seen:
            if error1[min_error_idx]<=error2[min_error_idx]:
                p=1
                pred = (feature>=thres).astype(int)
                err = error1[min_error_idx]
            else:
                p=-1
                pred = (feature<thres).astype(int)
                err = error2[min_error_idx]
            classifier_param = [f_idx,thres,p,err,pred]
            min_err_seen = min_error
    return classifier_param

def cascade_stage(X,y,set_TPR,set_FPR,n_est=50):
    weight_scalar = 0.5
    l = int(np.sum(y))
    m = len(y) - l
    wts = np.append(np.ones(l)/(2*l),np.ones(m)/(2*m))
    classifier_list=[]
    sum_aH = np.zeros(len(y))
    a_thres = 0
    for est in range(n_est):
        classifier_param = get_weak_classifier(X,y,wts)
        pred = classifier_param[-1]
        et = classifier_param[-2]
        beta_t = et/(1-et+1e-6)
        correct_pred_vec = np.abs(pred-y)
        wts = wts*(beta_t**(1-correct_pred_vec))
        alpha_t = np.log(1/(beta_t+1e-6))
        classifier_param.append(alpha_t)
        classifier_list.append(classifier_param)

        sum_aH = sum_aH + (alpha_t*pred)
        a_thres = a_thres + (alpha_t*weight_scalar)
        strong_H = sum_aH>=a_thres

        TPR = np.sum(strong_H[:l])/l
        FPR = np.sum(strong_H[l:])/m
        TNR = 1-FPR
        FNR = 1-TPR
        rep_FPR = np.sum(strong_H[l:])/1758
        if TPR>=set_TPR and FPR<=set_FPR:
            break

    perf_metrics = [TPR,FPR,rep_FPR,TNR,FNR]
    neg_idx_rm = (y==0) & (strong_H==0)
    X_rev = np.delete(X,neg_idx_rm,axis=0)
    y_rev = np.delete(y,neg_idx_rm,axis=0)

    return X_rev,y_rev,classifier_list,perf_metrics

def cascaded_AdaBoost():
  #train
  X,y = X_train_F,y_train_F
  num_pos_ex = int(np.sum(y))
  num_cascade_stages = 10
  stage_classifier_list = []
  perf_metric_list = []
  for i in range(num_cascade_stages):
      print(f'Stage : {i+1}')
      X,y,classifier_list,perf_metrics = cascade_stage(X,y,set_TPR=0.99,set_FPR=0.45,n_est=20)
      stage_classifier_list.append(classifier_list)
      perf_metric_list.append(perf_metrics)
      print(f'metrics : {perf_metrics}')
      if len(y[num_pos_ex:])==0:
          print('Training stopped')
          break

  perf_metric_list=np.array(perf_metric_list)
  stage_classifier_list=np.array(stage_classifier_list,dtype=object)
  np.savez_compressed(f'Haar_features_data/tranied_clf',x=stage_classifier_list,y=perf_metric_list)
  plt.plot(perf_metric_list[:,1],label='FPR')
  plt.plot(perf_metric_list[:,-1],label='FNR')
  plt.xlabel('stages')
  plt.ylabel('Perf. rate')
  plt.legend()
  plt.show()

  #test
  pred_list = []
  weight_scalar = 0.5
  l = int(np.sum(y_test_F))   #num_positive
  m = len(y_test_F) - l       #num_negetive
  sum_aH = np.zeros(len(y_test_F))
  a_thres = 0
  test_FPR_list,test_FNR_list= [],[]
  T_FN,T_TN = 0,0
  for classifiers in stage_classifier_list:
      # weak_pred_list = []
      for clf in classifiers:
          f_idx,thres,p,_,_,alpha_t = clf
          feature = X_test_F[:,f_idx]
          test_pred = (feature>=thres if p==1 else feature<thres).astype(int)
          # weak_pred_list.append(test_pred)
          sum_aH = sum_aH + (alpha_t*test_pred)
          a_thres = a_thres + (alpha_t*weight_scalar)
      strong_H = (sum_aH>=a_thres).astype(int)

      #only index for positive images as we remove negative images in each stage
      num_TP = np.sum(strong_H[:l]==1)
      T_FN = T_FN + l - num_TP
      num_FP = np.sum(strong_H[l:]==1)
      new_num_TN = m - num_FP
      T_TN = T_TN + new_num_TN
      test_FNR_list.append(T_FN/l)
      test_FPR_list.append(1-(T_TN/m))
      #positively classified samples for the next cascade stage
      X_test_F = X_test_F [np.where(strong_H == 1),:][0]
      y_test_F = y_test_F[np.where(strong_H==1)[0]]
      l = np.sum(y_test_F == 1)
      m = np.sum(y_test_F == 0)
      if (l == 0):
          print ('No more positive images')
          break
  print (test_FPR_list)
  print (test_FNR_list)

  plt.plot(test_FPR_list,label='FPR')
  plt.plot(test_FNR_list,label='FNR')
  plt.xlabel('stages')
  plt.ylabel('Perf. rate')
  plt.legend()
  plt.show()

cascaded_AdaBoost()

