# -*- coding: utf-8 -*-
"""CV_HW7_f.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uC4G5fDFSasI4oGPSoKfkwdQI-fnxDR1

Code
"""

# !pip install BitVector-3.4.9.tar.gz
# !unzip HW7-Auxilliary.zip

import numpy as np
import matplotlib.pyplot as plt
import cv2 as cv
import random
import math
import os
import sys
import BitVector
sys.path.append('/content/HW7-Auxilliary')
import vgg_and_resnet
from skimage import io
from tqdm import tqdm
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.utils import shuffle

#data location and categories
training_data_path = '/content/HW7-Auxilliary/data/training'
testing_data_path ='/content/HW7-Auxilliary/data/testing'

categories = ['cloudy','rain','shine','sunrise']

#VGG and RESNET models:
vgg = vgg_and_resnet.VGG19()
vgg.load_weights('/content/HW7-Auxilliary/vgg_normalized.pth')

encoder_name='resnet50' # Valid options ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']
resnet = vgg_and_resnet.CustomResNet(encoder=encoder_name)

#RGB to HSI
def RGB_2_Hue(image):
    image = image.astype('float')
    image /= 255.0
    R,G,B = image[:,:,0], image[:,:,1], image[:,:,2]
    I = (R+G+B)/3
    M = np.maximum(np.maximum(R,G),B)
    m = np.minimum(np.minimum(R,G),B)
    c = M-m
    S = np.zeros_like(I)
    S[c!=0] = 1 - m[c!=0]/I[c!=0]
    H = np.zeros_like(I)
    crit1 = (M==R) & (c!=0)
    H[crit1] = 60*(((G[crit1]-B[crit1])/c[crit1])%6)
    crit2 = (M==G) & (c!=0)
    H[crit2] = 60*(((B[crit2]-R[crit2])/c[crit2])+2)
    crit3 = (M==B) & (c!=0)
    H[crit3] = 60*(((R[crit3]-G[crit3])/c[crit3])+4)

    return H,S,I

#LBP histogram

def BV_encoding(BV_runs,P):
    if len(BV_runs) == 1 and BV_runs[0][0] == '0':
        encoding = 0
    elif len(BV_runs) == 1 and BV_runs[0][0] == '1':
        encoding = P
    elif len(BV_runs) > 2:
        encoding = P+1
    else:
        encoding = len(BV_runs[1])
    return encoding

def lbp(image_H, draw_plot=False):
    R = 1
    P = 8
    eps = 0.001
    hist_lbp = np.zeros(P+2)
    # hist_lbp_list = []
    image_H =  cv.resize(image_H, (64,64), interpolation=cv.INTER_AREA)
    H,W = image_H.shape
    for i in range(R,H-R):
        for j in range(R,W-R):
            pattern = []
            # print(f'pixel at {(i,j)}')
            for p in range(P):
                del_vals =  np.array([R*math.cos(2*math.pi*p/P), R*math.sin(2*math.pi*p/P)])
                del_vals[abs(del_vals) < eps] = 0
                k,l = int(i + del_vals[0]), int(j+del_vals[1])
                del_k, del_l = (i + del_vals[0]) - k, (j+del_vals[1]) - l
                if del_l < eps and del_k < eps:
                    imgVal_at_P = image_H[k,l]
                else:
                    imgVal_at_P = (1-del_k)*(1-del_l)*image_H[k,l] + (1-del_k)*del_l*image_H[k,l+1] + del_k*(1-del_l)*image_H[k+1,l] + del_k*del_l*image_H[k+1,l+1]
                pattern.append(1) if imgVal_at_P >= image_H[i,j] else pattern.append(0)
            # print(pattern)
            bv = BitVector.BitVector(bitlist=pattern)
            min_BV = BitVector.BitVector(intVal = min([int(bv << 1) for _ in range(P)]), size=P)
            BV_runs = min_BV.runs()
            hist_lbp[BV_encoding(BV_runs,P)]+=1

    if draw_plot:
        print('hist_lbp : ',hist_lbp)
        plt.bar(range(len(hist_lbp)), hist_lbp, )
        plt.title('Histogram of lbp')
        plt.show()

    return hist_lbp

# pattern_listA = lbp(image_H)

# Gram Matrix
def GramMatrix_feature(image, model='vgg', draw_plot=False, og_plt=True):
    image = vgg_and_resnet.transform.resize(image,(256,256))
    if model == 'vgg':
        feature = vgg(image)
    elif model == 'resnet_coarse':
        feature = resnet(image)[0]
    elif model == 'resnet_fine':
        feature = resnet(image)[1]
    c,h,w = feature.shape
    F = feature.reshape(c,-1)
    G = F@F.T

    if draw_plot:
        if og_plt:
          plt.imshow(G,cmap='hot', aspect='auto', interpolation='nearest')
        else: #downsampled plot
          if model == 'resnet_coarse':
            plt.imshow(G.reshape(32, 32, 32, 32).mean(axis=(1, 3)),cmap='hot', aspect='auto', interpolation='nearest')
          else:
            plt.imshow(G.reshape(32, 16, 32, 16).mean(axis=(1, 3)),cmap='hot', aspect='auto', interpolation='nearest')
        plt.colorbar()
        plt.title('Gram Matrix')
        plt.show()

    G /= c*h*w  # G /= np.max(G)
    V_gram = (G[np.triu_indices(G.shape[0])])
    # print(V_gram)
    return V_gram

# GramMatrix_feature(image)

# AdaIN - Channel normalization
def AdaIN_feature(image, model='vgg'):
    image = vgg_and_resnet.transform.resize(image,(256,256))
    if model == 'vgg':
        feature = vgg(image)
    elif model == 'resnet_coarse':
        feature = resnet(image)[0]
    elif model == 'resnet_fine':
        feature = resnet(image)[1]
    c,h,w = feature.shape
    F = feature.reshape(c,-1)
    u_l = np.mean(F,axis=1)
    sig_l = np.std(F,axis=1)
    V_norm = np.array(sum(zip(u_l,sig_l),()))

    return V_norm

# AdaIN_feature(image)

#load and label data
def data_load(categories, data_path=training_data_path):
    data_dir = sorted(os.listdir(data_path))
    categories_label = []
    img_data = []
    for img_name in data_dir:
        if img_name == '.DS_Store':
            continue
        img_path = os.path.join(data_path,img_name)
        img = io.imread(img_path)
        if len(img.shape) == 3 and img.shape[2]==3:
            if 'cloudy' in img_name.lower():
                categories_label.append(categories.index('cloudy'))
            elif 'rain' in img_name.lower():
                categories_label.append(categories.index('rain'))
            elif 'shine' in img_name.lower():
                categories_label.append(categories.index('shine'))
            elif 'sunrise' in img_name.lower():
                categories_label.append(categories.index('sunrise'))
            img_data.append(img)

    return categories_label, img_data

train_categories_label, train_img_data = data_load(categories, data_path=training_data_path)
test_categories_label, test_img_data = data_load(categories, data_path=testing_data_path)

# extract and save lbp features
def extractSave_lbp_features(img_data_src = train_img_data):
    hist_lbp_list = []
    for img in tqdm(img_data_src):
        img_H = RGB_2_Hue(img)[0]
        hist_lbp_list.append(lbp(img_H))
    data_src = 'train' if img_data_src == train_img_data else 'test'
    np.savez_compressed(f'{data_src}_lbp_features.npz',*hist_lbp_list)

extractSave_lbp_features(img_data_src=train_img_data)
extractSave_lbp_features(img_data_src=test_img_data)

#extract and save GM features based on diff. networks
def extractSave_GM_features(img_data_src=train_img_data, model='vgg'):
    V_gram_list = []
    for img in tqdm(img_data_src):
        V_gram_list.append(GramMatrix_feature(img,model))
    data_src = 'train' if img_data_src == train_img_data else 'test'
    np.savez_compressed(f'{data_src}_{model}_GM_features.npz',*V_gram_list)

extractSave_GM_features(train_img_data, 'vgg')
extractSave_GM_features(test_img_data, 'vgg')

extractSave_GM_features(train_img_data, 'resnet_coarse')
extractSave_GM_features(test_img_data, 'resnet_coarse')

extractSave_GM_features(train_img_data, 'resnet_fine')
extractSave_GM_features(test_img_data, 'resnet_fine')

#extract and save AdaIN features based on diff. networks
def extractSave_AdaIN_features(img_data_src=train_img_data, model='vgg'):
    V_norm_list = []
    for img in tqdm(img_data_src):
        V_norm_list.append(AdaIN_feature(img,model))
    data_src = 'train' if img_data_src == train_img_data else 'test'
    np.savez_compressed(f'{data_src}_{model}_AdaIN_features.npz',*V_norm_list)

extractSave_AdaIN_features(train_img_data, 'vgg')
extractSave_AdaIN_features(test_img_data, 'vgg')

extractSave_AdaIN_features(train_img_data, 'resnet_coarse')
extractSave_AdaIN_features(test_img_data, 'resnet_coarse')

extractSave_AdaIN_features(train_img_data, 'resnet_fine')
extractSave_AdaIN_features(test_img_data, 'resnet_fine')

# SVM Classifier model -> accuracy, confusion matrix
def SVM_classifer_model(Xtrain,Xtest,Ytrain=train_categories_label,Ytest=test_categories_label,categories=categories,fType='',net=''):
    Xtrain, Ytrain = shuffle(Xtrain, Ytrain, random_state=42)
    model = SVC(kernel='linear', decision_function_shape='ovo')
    model.fit(Xtrain,Ytrain)
    pred = model.predict(Xtest)
    accuracy = accuracy_score(Ytest,pred,normalize=True)
    report = classification_report(Ytest,pred)

    predTrain = model.predict(Xtrain)
    accuracyTrain = accuracy_score(Ytrain,predTrain,normalize=True)
    print(f'Train Accuracy: {accuracyTrain:.4f}')

    print(f'Test Accuracy: {accuracy:.4f}')
    print('Classification Report:')
    print(report)

    ## index to display
    # correct_index = (np.where(pred == Ytest)[0])[0]
    # misclassified_index = (np.where(pred != Ytest)[0])[0]

    correct_index = random.choice(np.where(pred == Ytest)[0])
    misclassified_index = random.choice(np.where(pred != Ytest)[0])

    # Display one correct classification
    plt.figure(figsize=(8, 4))

    plt.subplot(1, 2, 1)
    plt.imshow(test_img_data[correct_index])
    plt.title(f'Correctly Classified: {categories[Ytest[correct_index]]}')
    plt.axis('off')

    # Display one misclassification
    plt.subplot(1, 2, 2)
    plt.imshow(test_img_data[misclassified_index])
    plt.title(f'Misclassified as: {categories[pred[misclassified_index]]} (Actual: {categories[Ytest[misclassified_index]]})')
    plt.axis('off')
    plt.show()

    # Confusion Matrix
    conf_matrix = confusion_matrix(Ytest, pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=categories)
    disp.plot()
    plt.title(f'Confusion Matrix - {fType} {net}')
    plt.show()



#load saved lbp features
loaded_train_lbp = np.load('train_lbp_features.npz')
loaded_test_lbp = np.load('test_lbp_features.npz')

train_lbp = [loaded_train_lbp[key] for key in loaded_train_lbp]
test_lbp = [loaded_test_lbp[key] for key in loaded_test_lbp]

# load saved AdaIN features
loaded_train_AdaIN_vgg = np.load('train_vgg_AdaIN_features.npz')
loaded_test_AdaIN_vgg = np.load('test_vgg_AdaIN_features.npz')
loaded_train_AdaIN_resnet_coarse = np.load('train_resnet_coarse_AdaIN_features.npz')
loaded_test_AdaIN_resnet_coarse = np.load('test_resnet_coarse_AdaIN_features.npz')
loaded_train_AdaIN_resnet_fine = np.load('train_resnet_fine_AdaIN_features.npz')
loaded_test_AdaIN_resnet_fine= np.load('test_resnet_fine_AdaIN_features.npz')

train_AdaIN_vgg = [loaded_train_AdaIN_vgg[key] for key in loaded_train_AdaIN_vgg]
test_AdaIN_vgg = [loaded_test_AdaIN_vgg[key] for key in loaded_test_AdaIN_vgg]
train_AdaIN_resnet_coarse = [loaded_train_AdaIN_resnet_coarse[key] for key in loaded_train_AdaIN_resnet_coarse]
test_AdaIN_resnet_coarse = [loaded_test_AdaIN_resnet_coarse[key] for key in loaded_test_AdaIN_resnet_coarse]
train_AdaIN_resnet_fine = [loaded_train_AdaIN_resnet_fine[key] for key in loaded_train_AdaIN_resnet_fine]
test_AdaIN_resnet_fine = [loaded_test_AdaIN_resnet_fine[key] for key in loaded_test_AdaIN_resnet_fine]

# load saved GM features
loaded_train_GM_vgg = np.load('train_vgg_GM_features.npz')
loaded_test_GM_vgg = np.load('test_vgg_GM_features.npz')
loaded_train_GM_resnet_coarse = np.load('train_resnet_coarse_GM_features.npz')
loaded_test_GM_resnet_coarse = np.load('test_resnet_coarse_GM_features.npz')
loaded_train_GM_resnet_fine = np.load('train_resnet_fine_GM_features.npz')
loaded_test_GM_resnet_fine= np.load('test_resnet_fine_GM_features.npz')

train_GM_vgg = [loaded_train_GM_vgg[key] for key in loaded_train_GM_vgg]
test_GM_vgg = [loaded_test_GM_vgg[key] for key in loaded_test_GM_vgg]
train_GM_resnet_coarse = [loaded_train_GM_resnet_coarse[key] for key in loaded_train_GM_resnet_coarse]
test_GM_resnet_coarse = [loaded_test_GM_resnet_coarse[key] for key in loaded_test_GM_resnet_coarse]
train_GM_resnet_fine = [loaded_train_GM_resnet_fine[key] for key in loaded_train_GM_resnet_fine]
test_GM_resnet_fine = [loaded_test_GM_resnet_fine[key] for key in loaded_test_GM_resnet_fine]

#function to plot lbp histograms and GM for different classes
def plot_Hist_n_GM(og_plt):

  ## Class Histograms
  #lbp
  print('-----------------Histogram of LBP-----------------------')
  for i in range(len(categories)):
    print('Class : ',categories[i])
    idx = test_categories_label.index(i)
    test_img = test_img_data[idx]
    img_H = RGB_2_Hue(test_img)[0]
    hist_lbp = lbp(img_H,draw_plot=True)

  print('')
  ## Gram Matrix
  # vgg #resnet_coarse #resnet_fine
  print('--------------------GRAM MATRIX--------------------------')
  for net in ['vgg','resnet_coarse','resnet_fine']:
    print('Model : ',net)
    print('-----------------------------------------------------------------------------')
    for i in range(len(categories)):
      print('Class : ',categories[i])
      idx = test_categories_label.index(i)
      test_img = test_img_data[idx]
      V_gram = GramMatrix_feature(test_img,model=net,draw_plot=True,og_plt=og_plt)
      print('')

plot_Hist_n_GM(og_plt=True)



SVM_classifer_model(train_lbp,test_lbp,fType='lbp')

SVM_classifer_model(train_AdaIN_vgg,test_AdaIN_vgg,fType='AdaIN',net='vgg')

SVM_classifer_model(train_AdaIN_resnet_fine,test_AdaIN_resnet_fine,fType='AdaIN',net='resnet_fine')

SVM_classifer_model(train_AdaIN_resnet_coarse,test_AdaIN_resnet_coarse,fType='AdaIN',net='resnet_coarse')

SVM_classifer_model(train_GM_vgg,test_GM_vgg,fType='GM',net='vgg')

SVM_classifer_model(train_GM_resnet_fine,test_GM_resnet_fine,fType='GM',net='resnet_fine')

SVM_classifer_model(train_GM_resnet_coarse,test_GM_resnet_coarse,fType='GM',net='resnet_coarse')

